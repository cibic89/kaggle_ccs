{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import arff\n",
    "\n",
    "main_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(0, main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10236\n"
     ]
    }
   ],
   "source": [
    "raw_imgs_pth = os.path.join(main_dir, \"data\", \"raw\")+os.sep\n",
    "train_pth = os.path.join(raw_imgs_pth, \"train\")+os.sep\n",
    "tst_pth = os.path.join(raw_imgs_pth, \"test\")+os.sep\n",
    "\n",
    "intrm_img_trn_pth = os.path.join(main_dir, \"data\", \"interim\", \"train\")+os.sep\n",
    "intrm_img_tst_pth = os.path.join(main_dir, \"data\", \"interim\", \"test\")+os.sep\n",
    "\n",
    "intrm_img_trn_fnames_pth = os.path.join(intrm_img_trn_pth, \"filenames\")+os.sep\n",
    "intrm_img_trn_data_pth = os.path.join(intrm_img_trn_pth, \"data\")+os.sep\n",
    "\n",
    "intrm_img_tst_fnames_pth = os.path.join(intrm_img_tst_pth, \"filenames\")+os.sep\n",
    "intrm_img_tst_data_pth = os.path.join(intrm_img_tst_pth, \"data\")+os.sep\n",
    "\n",
    "paths = [intrm_img_trn_pth, intrm_img_tst_pth, intrm_img_trn_fnames_pth,\n",
    "         intrm_img_trn_data_pth, intrm_img_tst_fnames_pth, intrm_img_tst_data_pth]  # intrm_img_pth2\n",
    "for pth in paths:\n",
    "    os.makedirs(pth, exist_ok=True)\n",
    "    \n",
    "img_pth = pd.Series(glob(train_pth+\"*.jpg\")+glob(tst_pth+\"*.jpg\"))\n",
    "images_lst = []\n",
    "for file in img_pth:\n",
    "    images_lst += [file.rsplit('\\\\', 1)[-1]]\n",
    "print(len(images_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree_rot = 5\n",
    "# n_rot = int(360 / degree_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_timestamp = \"%Y/%m/%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2020/05/24 23:08:21\n",
      "Progress: 0%\n",
      "Finish time: 2020/05/24 23:08:21. This has taken 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Conv, ts to greyscale, resizes, and crops\n",
    "max_size = (480, 640)\n",
    "box_coord = (20, 40)\n",
    "(left, upper, right, lower) = (box_coord[0], box_coord[1], max_size[0]-box_coord[0], max_size[1]-box_coord[1])\n",
    "\n",
    "start_time = pd.to_datetime(\"now\")\n",
    "print(\"Start time:\", start_time.strftime(print_timestamp))\n",
    "\n",
    "for i, image_fname in enumerate(images_lst):\n",
    "    print(\"Progress: \"+str(int(round(((i+1)/((len(images_lst)+1))*100), 0)))+\"%\", end=\"\\r\")\n",
    "    try:\n",
    "        img = Image.open(img_pth[i]).convert(\"L\")\n",
    "    except Exception as error:\n",
    "        print(image_fname, repr(error))\n",
    "        continue\n",
    "     \n",
    "    # Rotate if necessary, resize, crop, normalise\n",
    "    s = img.size\n",
    "    if s[0] > s[1]:\n",
    "        img = img.rotate(90, expand=1)\n",
    "        s = img.size\n",
    "        print(img_pth[i], \"was rotated. Check if it has succeded manually (exif).\")\n",
    "    ratio = max_size[0]/s[0]\n",
    "    width, height = int(s[0]*ratio), int(s[1]*ratio)\n",
    "    \n",
    "    img = img.resize((width, height), Image.LANCZOS)\n",
    "    img = img.crop((left, upper, right, lower))\n",
    "    \n",
    "    # Normalise intensity\n",
    "    img = ImageOps.equalize(img)\n",
    "    img = ImageOps.autocontrast(img)\n",
    "    \n",
    "#     for interim_path in interim_paths:\n",
    "    if (\"tst_\" in image_fname) | (\"vld_\" in image_fname):\n",
    "        img.save(intrm_img_trn_pth+image_fname, quality=95)  # .replace(\".jpg\", \"_0.jpg\")\n",
    "    if (\"trn_\" in image_fname) | (\"vld_\" in image_fname):\n",
    "        img.save(intrm_img_tst_pth+image_fname, quality=95)\n",
    "    \n",
    "#     if \"tst_\" not in image_fname:\n",
    "#         for i in range(1, n_rot):\n",
    "#             img_copy = img.rotate(degree_rot*i)\n",
    "#             for interim_path in interim_paths:\n",
    "#                 img_copy.save(interim_path+image_fname.replace(\".jpg\", \"_\"+str(i))+\".jpg\", quality=95)\n",
    "\n",
    "#         img = ImageOps.mirror(img)\n",
    "#         for interim_path in interim_paths:\n",
    "#             img.save(interim_path+image_fname.replace(\".jpg\", \"_flip_0\")+\".jpg\", quality=95)\n",
    "#         for i in range(1, n_rot):\n",
    "#             img_copy = img.rotate(degree_rot*i)\n",
    "#             for interim_path in interim_paths:\n",
    "#                 img_copy.save(interim_path+image_fname.replace(\".jpg\", \"_flip_\"+str(i))+\".jpg\", quality=95)\n",
    "    \n",
    "print()\n",
    "\n",
    "finish_time = pd.to_datetime(\"now\")\n",
    "elapsed_time = finish_time - start_time\n",
    "print(\"Finish time:\", str(finish_time.strftime(print_timestamp))+\". This has taken \"+str(round(elapsed_time.seconds / 60, 0))+\" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_filenames(path, export=True, extra_str=\"\"):\n",
    "    images_df = [f for f in os.listdir(path) if isfile(join(path, f))]\n",
    "    images_df = pd.DataFrame([f for f in images_df if f.endswith(\".jpg\")], columns=[\"filename\"])\n",
    "    images_df[\"class\"] = images_df[\"filename\"].str.extract(\"(t\\d{1})\").astype(str)\n",
    "    \n",
    "    # images_df.to_csv(intrm_img_trn_pth+'complete_fnames'+extra_str+'.csv', index=False)\n",
    "    if export:\n",
    "    #     for interim_path in interim_paths:\n",
    "        arff.dump(path+'complete_fnames'+extra_str+'.arff'\n",
    "              , images_df.values\n",
    "              , relation='kaggle_ccs'\n",
    "              , names=images_df.columns)\n",
    "    return images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fnames_trn_df = prep_filenames(intrm_img_trn_pth, export=False, extra_str=\"_train_\")\n",
    "img_fnames_tst_df = prep_filenames(intrm_img_tst_pth, export=False, extra_str=\"_test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDivisors(n): \n",
    "    i = 1\n",
    "    n_w = n\n",
    "    divs = []\n",
    "    while (i <= n_w): \n",
    "        if (n_w % i==0) & (i >= 5) & (i <= 10):\n",
    "            drop_n = n-n_w\n",
    "            print(\"Int divisor for\", n_w, \"is\", str(i)+\". Drop\", drop_n,\"image groups.\")\n",
    "            return drop_n, i\n",
    "        if (n_w == i):\n",
    "            n_w -= 1\n",
    "            i = 0\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int divisor for 6730 is 5. Drop 0 image groups.\n"
     ]
    }
   ],
   "source": [
    "drp_img_n, cv_folds = printDivisors(len(img_fnames_trn_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfolding(filenames_s, class_s, export=True):\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=123)\n",
    "    kfold_ind = {}\n",
    "\n",
    "    for n, i in enumerate(skf.split(filenames_s, class_s)):\n",
    "        kfold_ind[n] = i\n",
    "        train_set = pd.concat([img_fnames_trn_df.loc[kfold_ind[n][0], filenames_s.name],\n",
    "                           img_fnames_trn_df.loc[kfold_ind[n][0], class_s.name]], axis=1)\n",
    "        val_set = pd.concat([img_fnames_trn_df.loc[kfold_ind[n][1],filenames_s.name],\n",
    "                               img_fnames_trn_df.loc[kfold_ind[n][1], class_s.name]], axis=1)\n",
    "#         print(len(train_set), len(val_set))\n",
    "    \n",
    "        if export:\n",
    "            print(\"Exporting fold\", str(n), \"to\", intrm_img_trn_fnames_pth)\n",
    "        #     train_set.to_csv(intrm_img_trn_fnames_pth+\"f\"+str(n)+\"_fnames_train.csv\", index=False)\n",
    "        #     val_set.to_csv(intrm_img_trn_fnames_pth+\"f\"+str(n)+\"_fnames_val.csv\", index=False)\n",
    "\n",
    "            arff.dump(intrm_img_trn_fnames_pth+\"f\"+str(n)+\"_fnames_train.arff\"\n",
    "              , train_set.values\n",
    "              , relation=\"f\"+str(n)+\"_train\"\n",
    "              , names=train_set.columns)\n",
    "\n",
    "            arff.dump(intrm_img_trn_fnames_pth+\"f\"+str(n)+\"_fnames_val.arff\"\n",
    "              , val_set.values\n",
    "              , relation=\"f\"+str(n)+\"_val\"\n",
    "              , names=val_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfolding(img_fnames_trn_df[\"filename\"], img_fnames_trn_df[\"class\"], export=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
